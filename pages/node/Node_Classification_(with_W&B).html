
<!DOCTYPE html>


<html lang="en" data-content_root="../../" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>2.2. Node Classification with W&amp;B &#8212; Graph Neural Network Tutorials</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../../_static/styles/theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../../_static/styles/bootstrap.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../../_static/styles/pydata-sphinx-theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />

  
  <link href="../../_static/vendor/fontawesome/6.5.2/css/all.min.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../../_static/vendor/fontawesome/6.5.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../_static/vendor/fontawesome/6.5.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../_static/vendor/fontawesome/6.5.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../../_static/pygments.css?v=fa44fd50" />
    <link rel="stylesheet" type="text/css" href="../../_static/styles/sphinx-book-theme.css?v=a3416100" />
    <link rel="stylesheet" type="text/css" href="../../_static/togglebutton.css?v=13237357" />
    <link rel="stylesheet" type="text/css" href="../../_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="../../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css?v=be8a1c11" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-thebe.css?v=4fa983c6" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-design.min.css?v=95c83b7e" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b" />
<link rel="preload" as="script" href="../../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b" />
  <script src="../../_static/vendor/fontawesome/6.5.2/js/all.min.js?digest=dfe6caa3a7d634c4db9b"></script>

    <script src="../../_static/documentation_options.js?v=9eb32ce0"></script>
    <script src="../../_static/doctools.js?v=9a2dae69"></script>
    <script src="../../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../../_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="../../_static/copybutton.js?v=7f8ff830"></script>
    <script src="../../_static/scripts/sphinx-book-theme.js?v=887ef09a"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../../_static/togglebutton.js?v=4a39c7ea"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="../../_static/design-tabs.js?v=f930bc37"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script async="async" src="../../_static/sphinx-thebe.js?v=c100c467"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'pages/node/Node_Classification_(with_W&B)';</script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="2.3. Point Cloud Classification" href="Point_Cloud_Classification.html" />
    <link rel="prev" title="2.1. Node Classification" href="Node_Classification.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-primary-sidebar-checkbox"/>
  <label class="overlay overlay-primary" for="pst-primary-sidebar-checkbox"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-secondary-sidebar-checkbox"/>
  <label class="overlay overlay-secondary" for="pst-secondary-sidebar-checkbox"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  
    
  

<a class="navbar-brand logo" href="../../intro.html">
  
  
  
  
  
    
    
      
    
    
    <img src="../../_static/logo.jpeg" class="logo__image only-light" alt="Graph Neural Network Tutorials - Home"/>
    <script>document.write(`<img src="../../_static/logo.jpeg" class="logo__image only-dark" alt="Graph Neural Network Tutorials - Home"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item">

 <script>
 document.write(`
   <button class="btn search-button-field search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
    <span class="search-button__default-text">Search</span>
    <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
   </button>
 `);
 </script></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="../../intro.html">
                    Graph Neural Network
                </a>
            </li>
        </ul>
        <ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../1_Introduction.html">1. Introduction</a></li>
<li class="toctree-l1 current active has-children"><a class="reference internal" href="Node.html">2. Nodes</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="Node_Classification.html">2.1. Node Classification</a></li>
<li class="toctree-l2 current active"><a class="current reference internal" href="#">2.2. Node Classification with W&amp;B</a></li>
<li class="toctree-l2"><a class="reference internal" href="Point_Cloud_Classification.html">2.3. Point Cloud Classification</a></li>
</ul><details open="open"><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../Graph.html">3. Graph</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../3_Graph_Classification.html">3.1. Graph Classification</a></li>
<li class="toctree-l2"><a class="reference internal" href="../9_Graph_Classification_with_PyG_and_W%26B.html">3.2. Graph Classification with W&amp;B</a></li>
</ul><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../Aggregation.html">4. Aggregation</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../7_Aggregation_Package.html">4.1. Customizing Aggregations within Message Passing</a></li>
<li class="toctree-l2"><a class="reference internal" href="../Aggregation%20Functions.html">4.2. Aggregation Functions</a></li>
</ul><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../Link.html">5. Links</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../10_Link_Prediction_on_MovieLens.html">5.1. Link Prediction</a></li>
<li class="toctree-l2"><a class="reference internal" href="../11_Link_Regression_on_Movielens.html">5.2. Link Regression</a></li>
</ul><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary>
</details></li>
<li class="toctree-l1"><a class="reference internal" href="../GATs.html">6. Graph Attention Networks</a></li>
<li class="toctree-l1"><a class="reference internal" href="../Spectral_GCL.html">7. Spectral methods</a></li>
<li class="toctree-l1"><a class="reference internal" href="../4_Scaling_GNNs.html">8. Scaling</a></li>
<li class="toctree-l1"><a class="reference internal" href="../6_GNN_Explanation.html">9. Explain using Captum</a></li>
<li class="toctree-l1"><a class="reference internal" href="../references.html">10. References</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><button class="sidebar-toggle primary-toggle btn btn-sm" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</button></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-launch-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Launch interactive content">
    <i class="fas fa-rocket"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://colab.research.google.com/github/khairulislam/Graph-Neural-Network/blob/master/docs/pages/node/Node_Classification_(with_W&B).ipynb" target="_blank"
   class="btn btn-sm dropdown-item"
   title="Launch on Colab"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  
    <img alt="Colab logo" src="../../_static/images/logo_colab.png">
  </span>
<span class="btn__text-container">Colab</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://github.com/khairulislam/Graph-Neural-Network" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="Source repository"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/khairulislam/Graph-Neural-Network/edit/master/docs/pages/node/Node_Classification_(with_W&B).ipynb" target="_blank"
   class="btn btn-sm btn-source-edit-button dropdown-item"
   title="Suggest edit"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-pencil-alt"></i>
  </span>
<span class="btn__text-container">Suggest edit</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/khairulislam/Graph-Neural-Network/issues/new?title=Issue%20on%20page%20%2Fpages/node/Node_Classification_(with_W&B).html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm btn-source-issues-button dropdown-item"
   title="Open an issue"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">Open issue</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="../../_sources/pages/node/Node_Classification_(with_W&B).ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="theme-switch fa-solid fa-sun fa-lg" data-mode="light"></i>
    <i class="theme-switch fa-solid fa-moon fa-lg" data-mode="dark"></i>
    <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"></i>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm pst-navbar-icon search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<button class="sidebar-toggle secondary-toggle btn btn-sm" title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</button>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Node Classification with W&B</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#training-a-multi-layer-perception-network-mlp">2.2.1. Training a Multi-layer Perception Network (MLP)</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#training-a-graph-neural-network-gnn">2.2.2. Training a Graph Neural Network (GNN)</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#using-w-b-sweeps">2.2.3. Using W&amp;B Sweeps</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#conclusion">2.2.4. Conclusion</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#optional-exercises">2.2.5. (Optional) Exercises</a></li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="node-classification-with-w-b">
<h1><span class="section-number">2.2. </span>Node Classification with W&amp;B<a class="headerlink" href="#node-classification-with-w-b" title="Link to this heading">#</a></h1>
<p><a class="reference external" href="https://colab.research.google.com/drive/1h3-vJGRVloF5zStxL5I0rSy4ZUPNsjy8">Previous: Introduction: Hands-on Graph Neural Networks</a></p>
<p>This tutorial will teach you how to apply <strong>Graph Neural Networks (GNNs) to the task of node classification</strong>.
Here, we are given the ground-truth labels of only a small subset of nodes, and want to infer the labels for all the remaining nodes (<em>transductive learning</em>).</p>
<p>To demonstrate, we make use of the <code class="docutils literal notranslate"><span class="pre">Cora</span></code> dataset, which is a <strong>citation network</strong> where nodes represent documents.
Each node is described by a 1433-dimensional bag-of-words feature vector.
Two documents are connected if there exists a citation link between them.
The task is to infer the category of each document (7 in total).</p>
<p>This dataset was first introduced by <a class="reference external" href="https://arxiv.org/abs/1603.08861">Yang et al. (2016)</a> as one of the datasets of the <code class="docutils literal notranslate"><span class="pre">Planetoid</span></code> benchmark suite.
We again can make use <a class="reference external" href="https://github.com/rusty1s/pytorch_geometric">PyTorch Geometric</a> for an easy access to this dataset via <a class="reference external" href="https://pytorch-geometric.readthedocs.io/en/latest/modules/datasets.html#torch_geometric.datasets.Planetoid"><code class="docutils literal notranslate"><span class="pre">torch_geometric.datasets.Planetoid</span></code></a>:</p>
<p><a href="https://colab.research.google.com/github/wandb/examples/blob/master/colabs/pyg/8_Node_Classification_(with_W&B).ipynb" target="_parent"><img alt="Open In Colab" src="https://colab.research.google.com/assets/colab-badge.svg" /></a></p>
<!--- @wandbcode{pytorch_geometric_example} --><img src="http://wandb.me/logo-im-png" width="400" alt="Weights & Biases" />
<!--- @wandbcode{pytorch_geometric_example} --><div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span># # Install required packages.

# !pip install -q torch-scatter -f https://data.pyg.org/whl/torch-${TORCH}.html
# !pip install -q torch-sparse -f https://data.pyg.org/whl/torch-${TORCH}.html
# !pip install -q git+https://github.com/pyg-team/pytorch_geometric.git
# !pip install -qqq wandb
</pre></div>
</div>
</div>
</div>
<p>Setup and login to Weights &amp; Biases</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>enable_wandb = True
if enable_wandb:
    import wandb
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>wandb.login()
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>import os
import pdb
import torch
import pandas

os.environ[&#39;TORCH&#39;] = torch.__version__
print(torch.__version__)
</pre></div>
</div>
</div>
</div>
<p>Helper function for visualization.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>import matplotlib.pyplot as plt
from sklearn.manifold import TSNE

def visualize(h, color):
    z = TSNE(n_components=2).fit_transform(h.detach().cpu().numpy())
    plt.figure(figsize=(10,10))
    plt.xticks([])
    plt.yticks([])
    plt.scatter(z[:, 0], z[:, 1], s=70, c=color, cmap=&quot;Set2&quot;)
    plt.show()

def embedding_to_wandb(h, color, key=&quot;embedding&quot;):
    num_components = h.shape[-1]
    df = pandas.DataFrame(data=h.detach().cpu().numpy(),
                        columns=[f&quot;c_{i}&quot; for i in range(num_components)])
    df[&quot;target&quot;] = color.detach().cpu().numpy().astype(&quot;str&quot;)
    cols = df.columns.tolist()
    df = df[cols[-1:] + cols[:-1]]
    wandb.log({key: df})
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>from torch_geometric.datasets import Planetoid
from torch_geometric.transforms import NormalizeFeatures

dataset = Planetoid(root=&#39;data/Planetoid&#39;, name=&#39;Cora&#39;, transform=NormalizeFeatures())

print()
print(f&#39;Dataset: {dataset}:&#39;)
print(&#39;======================&#39;)
print(f&#39;Number of graphs: {len(dataset)}&#39;)
print(f&#39;Number of features: {dataset.num_features}&#39;)
print(f&#39;Number of classes: {dataset.num_classes}&#39;)

data = dataset[0]  # Get the first graph object.

print()
print(data)
print(&#39;===========================================================================================================&#39;)

# Gather some statistics about the graph.
print(f&#39;Number of nodes: {data.num_nodes}&#39;)
print(f&#39;Number of edges: {data.num_edges}&#39;)
print(f&#39;Average node degree: {data.num_edges / data.num_nodes:.2f}&#39;)
print(f&#39;Number of training nodes: {data.train_mask.sum()}&#39;)
print(f&#39;Training node label rate: {int(data.train_mask.sum()) / data.num_nodes:.2f}&#39;)
print(f&#39;Has isolated nodes: {data.has_isolated_nodes()}&#39;)
print(f&#39;Has self-loops: {data.has_self_loops()}&#39;)
print(f&#39;Is undirected: {data.is_undirected()}&#39;)
</pre></div>
</div>
</div>
</div>
<p>Overall, this dataset is quite similar to the previously used <a class="reference external" href="https://pytorch-geometric.readthedocs.io/en/latest/modules/datasets.html#torch_geometric.datasets.KarateClub"><code class="docutils literal notranslate"><span class="pre">KarateClub</span></code></a> network.
We can see that the <code class="docutils literal notranslate"><span class="pre">Cora</span></code> network holds 2,708 nodes and 10,556 edges, resulting in an average node degree of 3.9.
For training this dataset, we are given the ground-truth categories of 140 nodes (20 for each class).
This results in a training node label rate of only 5%.</p>
<p>In contrast to <code class="docutils literal notranslate"><span class="pre">KarateClub</span></code>, this graph holds the additional attributes <code class="docutils literal notranslate"><span class="pre">val_mask</span></code> and <code class="docutils literal notranslate"><span class="pre">test_mask</span></code>, which denotes which nodes should be used for validation and testing.
Furthermore, we make use of <strong><a class="reference external" href="https://pytorch-geometric.readthedocs.io/en/latest/notes/introduction.html#data-transforms">data transformations</a> via <code class="docutils literal notranslate"><span class="pre">transform=NormalizeFeatures()</span></code></strong>.
Transforms can be used to modify your input data before inputting them into a neural network, <em>e.g.</em>, for normalization or data augmentation.
Here, we <a class="reference external" href="https://pytorch-geometric.readthedocs.io/en/latest/modules/transforms.html#torch_geometric.transforms.NormalizeFeatures">row-normalize</a> the bag-of-words input feature vectors.</p>
<p>We can further see that this network is undirected, and that there exists no isolated nodes (each document has at least one citation).</p>
<section id="training-a-multi-layer-perception-network-mlp">
<h2><span class="section-number">2.2.1. </span>Training a Multi-layer Perception Network (MLP)<a class="headerlink" href="#training-a-multi-layer-perception-network-mlp" title="Link to this heading">#</a></h2>
<p>In theory, we should be able to infer the category of a document solely based on its content, <em>i.e.</em> its bag-of-words feature representation, without taking any relational information into account.</p>
<p>Let’s verify that by constructing a simple MLP that solely operates on input node features (using shared weights across all nodes):</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>import torch
from torch.nn import Linear
import torch.nn.functional as F


class MLP(torch.nn.Module):
    def __init__(self, hidden_channels):
        super().__init__()
        torch.manual_seed(12345)
        self.lin1 = Linear(dataset.num_features, hidden_channels)
        self.lin2 = Linear(hidden_channels, dataset.num_classes)

    def forward(self, x):
        x = self.lin1(x)
        x = x.relu()
        x = F.dropout(x, p=0.5, training=self.training)
        x = self.lin2(x)
        return x

model = MLP(hidden_channels=16)
print(model)
</pre></div>
</div>
</div>
</div>
<p>(optionally) logging the data attributes to W&amp;B summary.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>if enable_wandb:
    wandb.init(project=&#39;node-classification&#39;)
    summary = dict()
    summary[&quot;data&quot;] = dict()
    summary[&quot;data&quot;][&quot;num_features&quot;] = dataset.num_features
    summary[&quot;data&quot;][&quot;num_classes&quot;] = dataset.num_classes
    summary[&quot;data&quot;][&quot;num_nodes&quot;] = data.num_nodes
    summary[&quot;data&quot;][&quot;num_edges&quot;] = data.num_edges
    summary[&quot;data&quot;][&quot;has_isolated_nodes&quot;] = data.has_isolated_nodes()
    summary[&quot;data&quot;][&quot;has_self_nodes&quot;] = data.has_self_loops()
    summary[&quot;data&quot;][&quot;is_undirected&quot;] = data.is_undirected()
    summary[&quot;data&quot;][&quot;num_training_nodes&quot;] = data.train_mask.sum()
    wandb.summary = summary
</pre></div>
</div>
</div>
</div>
<p>Our MLP is defined by two linear layers and enhanced by <a class="reference external" href="https://pytorch.org/docs/stable/generated/torch.nn.ReLU.html?highlight=relu#torch.nn.ReLU">ReLU</a> non-linearity and <a class="reference external" href="https://pytorch.org/docs/stable/generated/torch.nn.Dropout.html?highlight=dropout#torch.nn.Dropout">dropout</a>.
Here, we first reduce the 1433-dimensional feature vector to a low-dimensional embedding (<code class="docutils literal notranslate"><span class="pre">hidden_channels=16</span></code>), while the second linear layer acts as a classifier that should map each low-dimensional node embedding to one of the 7 classes.</p>
<p>Let’s train our simple MLP by following a similar procedure as described in <a class="reference external" href="https://colab.research.google.com/drive/1h3-vJGRVloF5zStxL5I0rSy4ZUPNsjy8">the first part of this tutorial</a>.
We again make use of the <strong>cross entropy loss</strong> and <strong>Adam optimizer</strong>.
This time, we also define a <strong><code class="docutils literal notranslate"><span class="pre">test</span></code> function</strong> to evaluate how well our final model performs on the test node set (which labels have not been observed during training).</p>
<p>We also visualize the embeddings of the untrained model to in visually comparing the progress made by the training process below.</p>
<p><strong>NOTE</strong>: <em>For W&amp;B mode, please set up the embedding projector from the setting panel of the logged table. More information can be found here: https://docs.wandb.ai/ref/app/features/panels/weave/embedding-projector</em></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>from IPython.display import Javascript  # Restrict height of output cell.
display(Javascript(&#39;&#39;&#39;google.colab.output.setIframeHeight(0, true, {maxHeight: 300})&#39;&#39;&#39;))

model = MLP(hidden_channels=16)

with torch.no_grad():
  out = model(data.x)

if enable_wandb:
    embedding_to_wandb(out, color=data.y, key=&quot;mlp/embedding/init&quot;)
else:
    visualize(out, data.y)

criterion = torch.nn.CrossEntropyLoss()  # Define loss criterion.
optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)  # Define optimizer.

def train():
      model.train()
      optimizer.zero_grad()  # Clear gradients.
      out = model(data.x)  # Perform a single forward pass.
      loss = criterion(out[data.train_mask], data.y[data.train_mask])  # Compute the loss solely based on the training nodes.
      loss.backward()  # Derive gradients.
      optimizer.step()  # Update parameters based on gradients.
      return loss

def test():
      model.eval()
      out = model(data.x)
      pred = out.argmax(dim=1)  # Use the class with highest probability.
      test_correct = pred[data.test_mask] == data.y[data.test_mask]  # Check against ground-truth labels.
      test_acc = int(test_correct.sum()) / int(data.test_mask.sum())  # Derive ratio of correct predictions.
      return test_acc

for epoch in range(1, 201):
    loss = train()
    if enable_wandb:
        wandb.log({&quot;mlp/loss&quot;: loss})
    print(f&#39;Epoch: {epoch:03d}, Loss: {loss:.4f}&#39;)
</pre></div>
</div>
</div>
</div>
<p>After training the model, we can call the <code class="docutils literal notranslate"><span class="pre">test</span></code> function to see how well our model performs on unseen labels.
Here, we are interested in the accuracy of the model, <em>i.e.</em>, the ratio of correctly classified nodes:</p>
<p>We also visualize the embeddings of the output. This will give us a visual hint as to how good the model is performing, when compared to the embeddings of the geometric models defined below.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>test_acc = test()

out = model(data.x)
if enable_wandb:
    embedding_to_wandb(out, color=data.y, key=&quot;mlp/embedding/trained&quot;)
    wandb.summary[&quot;mlp/accuracy&quot;] = test_acc
    wandb.log({&quot;mlp/accuracy&quot;: test_acc})
else:
  visualize(out, data.y)

print(f&#39;Test Accuracy: {test_acc:.4f}&#39;)
</pre></div>
</div>
</div>
</div>
<p>As one can see, our MLP performs rather bad with only about 59% test accuracy.
But why does the MLP do not perform better?
The main reason for that is that this model suffers from heavy overfitting due to only having access to a <strong>small amount of training nodes</strong>, and therefore generalizes poorly to unseen node representations.</p>
<p>It also fails to incorporate an important bias into the model: <strong>Cited papers are very likely related to the category of a document</strong>.
That is exactly where Graph Neural Networks come into play and can help to boost the performance of our model.</p>
</section>
<section id="training-a-graph-neural-network-gnn">
<h2><span class="section-number">2.2.2. </span>Training a Graph Neural Network (GNN)<a class="headerlink" href="#training-a-graph-neural-network-gnn" title="Link to this heading">#</a></h2>
<p>We can easily convert our MLP to a GNN by swapping the <code class="docutils literal notranslate"><span class="pre">torch.nn.Linear</span></code> layers with PyG’s GNN operators.</p>
<p>Following-up on <a class="reference external" href="https://colab.research.google.com/drive/1h3-vJGRVloF5zStxL5I0rSy4ZUPNsjy8">the first part of this tutorial</a>, we replace the linear layers by the <a class="reference external" href="https://pytorch-geometric.readthedocs.io/en/latest/modules/nn.html#torch_geometric.nn.conv.GCNConv"><code class="docutils literal notranslate"><span class="pre">GCNConv</span></code></a> module.
To recap, the <strong>GCN layer</strong> (<a class="reference external" href="https://arxiv.org/abs/1609.02907">Kipf et al. (2017)</a>) is defined as</p>
<div class="math notranslate nohighlight">
\[
\mathbf{x}_v^{(\ell + 1)} = \mathbf{W}^{(\ell + 1)} \sum_{w \in \mathcal{N}(v) \, \cup \, \{ v \}} \frac{1}{c_{w,v}} \cdot \mathbf{x}_w^{(\ell)}
\]</div>
<p>where <span class="math notranslate nohighlight">\(\mathbf{W}^{(\ell + 1)}\)</span> denotes a trainable weight matrix of shape <code class="docutils literal notranslate"><span class="pre">[num_output_features,</span> <span class="pre">num_input_features]</span></code> and <span class="math notranslate nohighlight">\(c_{w,v}\)</span> refers to a fixed normalization coefficient for each edge.
In contrast, a single <code class="docutils literal notranslate"><span class="pre">Linear</span></code> layer is defined as</p>
<div class="math notranslate nohighlight">
\[
\mathbf{x}_v^{(\ell + 1)} = \mathbf{W}^{(\ell + 1)} \mathbf{x}_v^{(\ell)}
\]</div>
<p>which does not make use of neighboring node information.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>from torch_geometric.nn import GCNConv


class GCN(torch.nn.Module):
    def __init__(self, hidden_channels):
        super().__init__()
        torch.manual_seed(1234567)
        self.conv1 = GCNConv(dataset.num_features, hidden_channels)
        self.conv2 = GCNConv(hidden_channels, dataset.num_classes)

    def forward(self, x, edge_index):
        x = self.conv1(x, edge_index)
        x = x.relu()
        x = F.dropout(x, p=0.5, training=self.training)
        x = self.conv2(x, edge_index)
        return x

model = GCN(hidden_channels=16)
print(model)
</pre></div>
</div>
</div>
</div>
<p>Let’s visualize the node embeddings of our <strong>untrained</strong> GCN network.
For visualization, we make use of <a class="reference external" href="https://scikit-learn.org/stable/modules/generated/sklearn.manifold.TSNE.html"><strong>TSNE</strong></a> to embed our 7-dimensional node embeddings onto a 2D plane.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>model = GCN(hidden_channels=16)
model.eval()

out = model(data.x, data.edge_index)

if enable_wandb:
    embedding_to_wandb(out, color=data.y, key=&quot;gcn/embedding/init&quot;)
else:
    visualize(out, data.y)
</pre></div>
</div>
</div>
</div>
<p>We certainly can do better by training our model.
The training and testing procedure is once again the same, but this time we make use of the node features <code class="docutils literal notranslate"><span class="pre">x</span></code> <strong>and</strong> the graph connectivity <code class="docutils literal notranslate"><span class="pre">edge_index</span></code> as input to our GCN model.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>from IPython.display import Javascript  # Restrict height of output cell.
display(Javascript(&#39;&#39;&#39;google.colab.output.setIframeHeight(0, true, {maxHeight: 300})&#39;&#39;&#39;))

model = GCN(hidden_channels=16)
if enable_wandb:
    wandb.watch(model)

optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)
criterion = torch.nn.CrossEntropyLoss()

def train():
      model.train()
      optimizer.zero_grad()  # Clear gradients.
      out = model(data.x, data.edge_index)  # Perform a single forward pass.
      loss = criterion(out[data.train_mask], data.y[data.train_mask])  # Compute the loss solely based on the training nodes.
      loss.backward()  # Derive gradients.
      optimizer.step()  # Update parameters based on gradients.
      return loss

def test():
      model.eval()
      out = model(data.x, data.edge_index)
      pred = out.argmax(dim=1)  # Use the class with highest probability.
      test_correct = pred[data.test_mask] == data.y[data.test_mask]  # Check against ground-truth labels.
      test_acc = int(test_correct.sum()) / int(data.test_mask.sum())  # Derive ratio of correct predictions.
      return test_acc


for epoch in range(1, 101):
    loss = train()
    if enable_wandb:
        wandb.log({&quot;gcn/loss&quot;: loss})
    print(f&#39;Epoch: {epoch:03d}, Loss: {loss:.4f}&#39;)
</pre></div>
</div>
</div>
</div>
<p>After training the model, we can check its test accuracy:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>test_acc = test()
print(f&#39;Test Accuracy: {test_acc:.4f}&#39;)
</pre></div>
</div>
</div>
</div>
<p><strong>There it is!</strong>
By simply swapping the linear layers with GNN layers, we can reach <strong>81.5% of test accuracy</strong>!
This is in stark contrast to the 59% of test accuracy obtained by our MLP, indicating that relational information plays a crucial role in obtaining better performance.</p>
<p>We can also verify that once again by looking at the output embeddings of our <strong>trained</strong> model, which now produces a far better clustering of nodes of the same category.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>model.eval()

out = model(data.x, data.edge_index)

if enable_wandb:
    wandb.summary[&quot;gcn/accuracy&quot;] = test_acc
    wandb.log({&quot;gcn/accuracy&quot;: test_acc})
    embedding_to_wandb(out, color=data.y, key=&quot;gcn/embedding/trained&quot;)
    wandb.finish()
else:
    visualize(out, data.y)
</pre></div>
</div>
</div>
</div>
</section>
<section id="using-w-b-sweeps">
<h2><span class="section-number">2.2.3. </span>Using W&amp;B Sweeps<a class="headerlink" href="#using-w-b-sweeps" title="Link to this heading">#</a></h2>
<p>In this section, we’ll look into how we can use <a class="reference external" href="https://wandb.ai/site/sweeps/">W&amp;B Sweeps</a> to perform a hyper-parameter search for the GCN. For this to work, it is essential for wandb to be enabled, i.e., <code class="docutils literal notranslate"><span class="pre">enable_wandb</span></code> should be set to <code class="docutils literal notranslate"><span class="pre">True</span></code>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>assert enable_wandb, &quot;W&amp;B not enabled. Please, enable W&amp;B and restart the notebook&quot;
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>import tqdm

def agent_fn():
    wandb.init()
    model = GCN(hidden_channels=wandb.config.hidden_channels)
    wandb.watch(model)

    with torch.no_grad():
      out = model(data.x, data.edge_index)
      embedding_to_wandb(out, color=data.y, key=&quot;gcn/embedding/init&quot;)

    optimizer = torch.optim.Adam(model.parameters(), lr=wandb.config.lr, weight_decay=wandb.config.weight_decay)
    criterion = torch.nn.CrossEntropyLoss()

    def train():
          model.train()
          optimizer.zero_grad()  # Clear gradients.
          out = model(data.x, data.edge_index)  # Perform a single forward pass.
          loss = criterion(out[data.train_mask], data.y[data.train_mask])  # Compute the loss solely based on the training nodes.
          loss.backward()  # Derive gradients.
          optimizer.step()  # Update parameters based on gradients.
          return loss

    def test():
          model.eval()
          out = model(data.x, data.edge_index)
          pred = out.argmax(dim=1)  # Use the class with highest probability.
          test_correct = pred[data.test_mask] == data.y[data.test_mask]  # Check against ground-truth labels.
          test_acc = int(test_correct.sum()) / int(data.test_mask.sum())  # Derive ratio of correct predictions.
          return test_acc


    for epoch in tqdm.tqdm(range(1, 101)):
        loss = train()
        wandb.log({&quot;gcn/loss&quot;: loss})


    model.eval()

    out = model(data.x, data.edge_index)
    test_acc = test()
    wandb.summary[&quot;gcn/accuracy&quot;] = test_acc
    wandb.log({&quot;gcn/accuracy&quot;: test_acc})
    embedding_to_wandb(out, color=data.y, key=&quot;gcn/embedding/trained&quot;)
    wandb.finish()
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>sweep_config = {
    &quot;name&quot;: &quot;gcn-sweep&quot;,
    &quot;method&quot;: &quot;bayes&quot;,
    &quot;metric&quot;: {
        &quot;name&quot;: &quot;gcn/accuracy&quot;,
        &quot;goal&quot;: &quot;maximize&quot;,
    },
    &quot;parameters&quot;: {
        &quot;hidden_channels&quot;: {
            &quot;values&quot;: [8, 16, 32]
        },
        &quot;weight_decay&quot;: {
            &quot;distribution&quot;: &quot;normal&quot;,
            &quot;mu&quot;: 5e-4,
            &quot;sigma&quot;: 1e-5,
        },
        &quot;lr&quot;: {
            &quot;min&quot;: 1e-4,
            &quot;max&quot;: 1e-3
        }
    }
}

# Register the Sweep with W&amp;B
sweep_id = wandb.sweep(sweep_config, project=&quot;node-classification&quot;)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span># Run the Sweeps agent
wandb.agent(sweep_id, project=&quot;node-classification&quot;, function=agent_fn, count=50)
</pre></div>
</div>
</div>
</div>
</section>
<section id="conclusion">
<h2><span class="section-number">2.2.4. </span>Conclusion<a class="headerlink" href="#conclusion" title="Link to this heading">#</a></h2>
<p>In this chapter, you have seen how to apply GNNs to real-world problems, and, in particular, how they can effectively be used for boosting a model’s performance.
In the next section, we will look into how GNNs can be used for the task of graph classification.</p>
<p><a class="reference external" href="https://colab.research.google.com/drive/1I8a0DfQ3fI7Njc62__mVXUlcAleUclnb">Next: Graph Classification with Graph Neural Networks</a></p>
</section>
<section id="optional-exercises">
<h2><span class="section-number">2.2.5. </span>(Optional) Exercises<a class="headerlink" href="#optional-exercises" title="Link to this heading">#</a></h2>
<ol class="arabic simple">
<li><p>To achieve better model performance and to avoid overfitting, it is usually a good idea to select the best model based on an additional validation set.
The <code class="docutils literal notranslate"><span class="pre">Cora</span></code> dataset provides a validation node set as <code class="docutils literal notranslate"><span class="pre">data.val_mask</span></code>, but we haven’t used it yet.
Can you modify the code to select and test the model with the highest validation performance?
This should bring test performance to <strong>82% accuracy</strong>.</p></li>
<li><p>How does <code class="docutils literal notranslate"><span class="pre">GCN</span></code> behave when increasing the hidden feature dimensionality or the number of layers?
Does increasing the number of layers help at all?</p></li>
<li><p>You can try to use different GNN layers to see how model performance changes. What happens if you swap out all <code class="docutils literal notranslate"><span class="pre">GCNConv</span></code> instances with <a class="reference external" href="https://pytorch-geometric.readthedocs.io/en/latest/modules/nn.html#torch_geometric.nn.conv.GATConv"><code class="docutils literal notranslate"><span class="pre">GATConv</span></code></a> layers that make use of attention? Try to write a 2-layer <code class="docutils literal notranslate"><span class="pre">GAT</span></code> model that makes use of 8 attention heads in the first layer and 1 attention head in the second layer, uses a <code class="docutils literal notranslate"><span class="pre">dropout</span></code> ratio of <code class="docutils literal notranslate"><span class="pre">0.6</span></code> inside and outside each <code class="docutils literal notranslate"><span class="pre">GATConv</span></code> call, and uses a <code class="docutils literal notranslate"><span class="pre">hidden_channels</span></code> dimensions of <code class="docutils literal notranslate"><span class="pre">8</span></code> per head.</p></li>
</ol>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>from torch_geometric.nn import GATConv


class GAT(torch.nn.Module):
    def __init__(self, hidden_channels, heads):
        super().__init__()
        torch.manual_seed(1234567)
        self.conv1 = GATConv(...)  # TODO
        self.conv2 = GATConv(...)  # TODO

    def forward(self, x, edge_index):
        x = F.dropout(x, p=0.6, training=self.training)
        x = self.conv1(x, edge_index)
        x = F.elu(x)
        x = F.dropout(x, p=0.6, training=self.training)
        x = self.conv2(x, edge_index)
        return x

model = GAT(hidden_channels=8, heads=8)
print(model)

optimizer = torch.optim.Adam(model.parameters(), lr=0.005, weight_decay=5e-4)
criterion = torch.nn.CrossEntropyLoss()

def train():
      model.train()
      optimizer.zero_grad()  # Clear gradients.
      out = model(data.x, data.edge_index)  # Perform a single forward pass.
      loss = criterion(out[data.train_mask], data.y[data.train_mask])  # Compute the loss solely based on the training nodes.
      loss.backward()  # Derive gradients.
      optimizer.step()  # Update parameters based on gradients.
      return loss

def test(mask):
      model.eval()
      out = model(data.x, data.edge_index)
      pred = out.argmax(dim=1)  # Use the class with highest probability.
      correct = pred[mask] == data.y[mask]  # Check against ground-truth labels.
      acc = int(correct.sum()) / int(mask.sum())  # Derive ratio of correct predictions.
      return acc


for epoch in range(1, 201):
    loss = train()
    val_acc = test(data.val_mask)
    test_acc = test(data.test_mask)
    print(f&#39;Epoch: {epoch:03d}, Loss: {loss:.4f}, Val: {val_acc:.4f}, Test: {test_acc:.4f}&#39;)
</pre></div>
</div>
</div>
</div>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./pages\node"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="Node_Classification.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title"><span class="section-number">2.1. </span>Node Classification</p>
      </div>
    </a>
    <a class="right-next"
       href="Point_Cloud_Classification.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title"><span class="section-number">2.3. </span>Point Cloud Classification</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#training-a-multi-layer-perception-network-mlp">2.2.1. Training a Multi-layer Perception Network (MLP)</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#training-a-graph-neural-network-gnn">2.2.2. Training a Graph Neural Network (GNN)</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#using-w-b-sweeps">2.2.3. Using W&amp;B Sweeps</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#conclusion">2.2.4. Conclusion</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#optional-exercises">2.2.5. (Optional) Exercises</a></li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Md Khairul Islam
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      © Copyright 2024.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b"></script>
<script src="../../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>